{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf97d205",
   "metadata": {},
   "source": [
    "# Neuronale Netze"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd925e6",
   "metadata": {},
   "source": [
    "## Aufgabe 1: Tensorflow Playground\n",
    "\n",
    "Wir möchten uns mit dem Verhalten von neuronalen Netzen vertraut machen\n",
    "\n",
    "1. Gehen Sie auf https://playground.tensorflow.org \n",
    "2. Machen Sie sich mit den Features vertraut\n",
    "3. Was kodieren die Farben Blau und Orange?\n",
    "\n",
    "Blau zeigt positive Werte und Orange negative Werte. Sowohl bei den Gewichten als im Output. \n",
    "\n",
    "4. Wie werden die Punkte klassifiziert?\n",
    "\n",
    "Wie in der Vorlesung gezeigt wird bei binärer Klassifikation die Sigmoid Funktion verwendet und anschließend ein Tresholding (um auf -1 oder 1 zu runden)\n",
    "\n",
    "5. Wie können Sie sehen welche Feature Importance das Modell errechnet hat?\n",
    "\n",
    "Die Größe der Gewichte entspricht der dicke der Linien im Modell, um so größer (im Absolutbetrag) diese sind um so wichtiger erachtet das Modell diese.\n",
    "\n",
    "6. Welche der gezeigten Feature Engineering Methoden kennen Sie bereits?\n",
    "\n",
    "Implementiert haben wir bereits die Polynomiellen Features $X_1^2$, $X_2^2$, $X_1 X_2$. $sin(X_1), sin(X_2)$ haben wir nicht explizit gesehen. Dieses ist hilfreich, wenn die Daten spiralförmig angeordnet sind.\n",
    "\n",
    "7. Versuchen Sie verschiedene Parameter auf verschiedenen Datensätzen und beobachten Sie die Modelle um ein Gefühl für das Verhalten zu bekommen.\n",
    "\n",
    "    - Generell gilt: mehr Layer und Neuronen sorgen für flexiblere Modelle, aber das Training dauert lang. Regularisierung ist bei vielen Layern und Neuronen wichtig. Die Learning Rate kann zu hoch eingestellt sein, dass konvergiert das Modell nicht. Wenn die LR zu gering ist konvergiert das Modell nur sehr langsam. \n",
    "\n",
    "    - Man kann den Variance / Bias Tradeoff für viele Parameter gut sehen. \n",
    "\n",
    "    - Das Training mit ReLU ist schneller als mit z.B. tanh.\n",
    "\n",
    "8. Deep Learning. Wenn Sie die Anzahl der Hidden Layer stark erhöhen spricht man von _Deep Learning_. Probieren Sie aus ob Sie mit Deep Learning und nur den Features $X_1$ und $X_2$ die spiralförmigen Datensätze separieren können.\n",
    "\n",
    "Die vielen Layer sorgen dafür, dass das Modell deutlich flexibler wird und somit auch Sinus und Kosinus approximiert werden kann. Deep Learning ist sehr mächtig, neight aber auch wie die Random Forests zu overfitting. Zudem kommen Schwierigkeiten beim Training der Modelle (vanishing / exploding Gradients, sehr große Modelle die nur langsam Trainieren) und noch vieles mehr. Die meisten Probleme sind heutzutage aber lösbar und haben Mitigationsstrategien."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4a37b6",
   "metadata": {},
   "source": [
    "# Aufgabe 2: MNIST\n",
    "\n",
    "MNIST steht für Modified National Institute of Standards and Technology database und enthält Bilder von Zahlen die von Handschriften stammen. Diese mit neuronalen Netzen zu erkennen gilt als das \"Hello World\" von Bilderkennung mit Machine Learning.\n",
    "\n",
    "1. Laden Sie die Daten und analysieren Sie diese (datentyp, plotting etc)\n",
    "2. Machen Sie einen Test/Traning Split der Daten\n",
    "3. Bauen Sie eine Pipeline mit dem `MLPClassifier`\n",
    "4. Sehen Sie wie gut Sie abschneiden mit verschiedenen Netztopologien und messen Sie diese mit `classification_report`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "613b02d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x432 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets, metrics, svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "mnist = datasets.load_digits()\n",
    "\n",
    "_, axes = plt.subplots(nrows=1, ncols=10, figsize=(15, 6))\n",
    "for ax, image, label in zip(axes, mnist.images, mnist.target):\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(image, cmap=plt.cm.gray_r, interpolation=\"nearest\")\n",
    "    ax.set_title(\"Training: %i\" % label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7352220c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.9796    0.9897        49\n",
      "           1     0.9400    1.0000    0.9691        47\n",
      "           2     0.9615    0.9804    0.9709        51\n",
      "           3     0.9474    0.9474    0.9474        38\n",
      "           4     0.9744    1.0000    0.9870        38\n",
      "           5     0.9773    0.9773    0.9773        44\n",
      "           6     0.9744    0.9744    0.9744        39\n",
      "           7     1.0000    0.9808    0.9903        52\n",
      "           8     0.9487    0.9024    0.9250        41\n",
      "           9     0.9800    0.9608    0.9703        51\n",
      "\n",
      "    accuracy                         0.9711       450\n",
      "   macro avg     0.9704    0.9703    0.9701       450\n",
      "weighted avg     0.9714    0.9711    0.9710       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n = len(mnist.images)\n",
    "X = mnist.images.reshape((n, -1))  # flatten\n",
    "y = mnist.target\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "\n",
    "clf = MLPClassifier(random_state=0, max_iter=300)\n",
    "pipe = Pipeline([(\"scaler\", MinMaxScaler()), (\"NN\", clf)])\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "predicted = pipe.predict(X_test)\n",
    "\n",
    "print(metrics.classification_report(y_test, predicted, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1c0c3356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.9796    0.9897        49\n",
      "           1     0.9400    1.0000    0.9691        47\n",
      "           2     0.9808    1.0000    0.9903        51\n",
      "           3     0.9730    0.9474    0.9600        38\n",
      "           4     0.9744    1.0000    0.9870        38\n",
      "           5     0.9773    0.9773    0.9773        44\n",
      "           6     0.9750    1.0000    0.9873        39\n",
      "           7     1.0000    0.9808    0.9903        52\n",
      "           8     1.0000    0.9268    0.9620        41\n",
      "           9     0.9804    0.9804    0.9804        51\n",
      "\n",
      "    accuracy                         0.9800       450\n",
      "   macro avg     0.9801    0.9792    0.9793       450\n",
      "weighted avg     0.9805    0.9800    0.9799       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(random_state=0, max_iter=300, hidden_layer_sizes=(100, 100, 100))\n",
    "\n",
    "pipe = Pipeline([(\"scaler\", MinMaxScaler()), (\"NN\", clf)])\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "predicted = pipe.predict(X_test)\n",
    "\n",
    "print(metrics.classification_report(y_test, predicted, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15fa264",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (ipykernel)",
   "language": "python",
   "name": "python3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
