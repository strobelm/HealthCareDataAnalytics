{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2878889",
   "metadata": {},
   "source": [
    "# Übung 7: Regularisierung und  Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25628840",
   "metadata": {},
   "source": [
    "#### Aufgabe 1\n",
    "\n",
    "In der Vorlesung haben wir gelernt, dass die L1 Regulierung dazu neigt viele Koeffizieten auf 0 zu setzen. \n",
    "\n",
    "Benutzen Sie die Daten der männlichen Raucher und führen Sie darauf eine Regression mit unterschiedlich starker Regularisierung, sowohl L1 als auch L2, durch. Schauen Sie sich dabei verschiedene statistische Kennzahlen der Regressionskoeffizieten wie Mittelwert, Min/Max und Quantile an. Zählen Sie wie viele Koeffizieten dabei 0 sind. Was stellen Sie fest?\n",
    "\n",
    "#### Aufgabe 2\n",
    "\n",
    "Nehme Sie nun alle Daten aus der 'insurance.csv' und trainieren Sie eine Regression mit einem DecisionTree. Variieren Sie der Parameter 'max_depth' und 'min_sample_leaves' und suchen Sie die beste Kombination.\n",
    "\n",
    "#### Aufgabe 3\n",
    "\n",
    "Wie Sie in Aufgabe 2 gesehen haben ist es sehr aufwändig die richtigen Parameter zu finden. Zum Glück kann scikit-learn dies automatisieren. Lesen Sie sich dafür in 'GridSearchCV' ein und finden Sie die besten Parameter für 'max_depth', 'min_samples_split' und 'min_samples_leaf'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d50d8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, OrdinalEncoder, PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5c3bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance = pd.read_csv(\"data/insurance.csv\")\n",
    "insurance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc36293c",
   "metadata": {},
   "outputs": [],
   "source": [
    "male_smokers = insurance[\n",
    "    (insurance[\"sex\"] == \"male\") & (insurance[\"smoker\"] == \"yes\")\n",
    "].sort_values(by=[\"bmi\"])\n",
    "\n",
    "X = male_smokers[\"bmi\"].to_numpy().reshape(-1, 1)\n",
    "y = male_smokers[\"expenses\"].to_numpy().reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d897f94",
   "metadata": {},
   "source": [
    "## Aufgabe 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef13fb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# benutzen Sie np.abs(coeff) < eps statt wirklich nach 0 zu suchen\n",
    "eps = 1e-8\n",
    "\n",
    "poly_features = PolynomialFeatures(degree=50, include_bias=False)\n",
    "std_scaler = MinMaxScaler()\n",
    "# lam muss in der Schleife gesetzt werden\n",
    "lam = None\n",
    "ridge_reg = Ridge(alpha=lam)\n",
    "pipe_ridge = Pipeline(\n",
    "    [\n",
    "        (\"std_scaler\", std_scaler),\n",
    "        (\"poly_features\", poly_features),\n",
    "        (\"ridge\", ridge_reg),\n",
    "    ]\n",
    ")\n",
    "# Parameter der ridge regression aus der pipeline\n",
    "# pipe_lasso.get_params()[\"ridge\"].coef_\n",
    "\n",
    "# analog zu oben\n",
    "# pipe_ridge = ...\n",
    "\n",
    "# Schleife über lam(bda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da7e174",
   "metadata": {},
   "source": [
    "## Aufgabe 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca49be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = insurance.drop(columns=[\"expenses\"], axis=1)\n",
    "y = insurance[\"expenses\"].to_numpy().reshape(-1, 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9a8fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "numeric_features = [\"age\", \"bmi\", \"children\"]\n",
    "ordinal_features = [\"sex\", \"smoker\"]\n",
    "\n",
    "numeric_transformer = Pipeline(  # Decision Tree braucht kein Scaling\n",
    "    steps=[\n",
    "        (\n",
    "            \"imputer\",\n",
    "            SimpleImputer(strategy=\"mean\"),\n",
    "        ),\n",
    "        (\"poly_features\", PolynomialFeatures(degree=8)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "ordinal_transfomer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"ordinal_encoding\", OrdinalEncoder()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "y_preprocessor = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "    ]\n",
    ")\n",
    "\n",
    "X_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat_ordinal\", ordinal_transfomer, ordinal_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "X_train_prepared = X_preprocessor.fit_transform(X_train)\n",
    "y_train_prepared = y_preprocessor.fit_transform(y_train)\n",
    "\n",
    "# Doppelschleife über max_depth und min_sample leaves"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd0518f",
   "metadata": {},
   "source": [
    "## Aufgabe 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f4485c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "square = lambda n: [x**2 for x in np.arange(1, n)]\n",
    "param_grid = {\n",
    "    \"max_depth\": square(10),\n",
    "    \"min_samples_split\": square(10),\n",
    "    \"min_samples_leaf\": square(10),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f51d4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeRegressor(**best_params)\n",
    "clf.fit(X_train_prepared, y_train_prepared)\n",
    "\n",
    "print(f\"Train score: {clf.score(X_train_prepared, y_train_prepared)}\")\n",
    "print(f\"Test score: {clf.score(X_test_prepared, y_test_prepared)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (ipykernel)",
   "language": "python",
   "name": "python3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
